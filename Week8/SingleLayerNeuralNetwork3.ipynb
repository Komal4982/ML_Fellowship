{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.139371Z",
     "start_time": "2019-06-07T03:17:39.136919Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.221446Z",
     "start_time": "2019-06-07T03:17:39.141083Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.239864Z",
     "start_time": "2019-06-07T03:17:39.223337Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.250862Z",
     "start_time": "2019-06-07T03:17:39.242172Z"
    }
   },
   "outputs": [],
   "source": [
    "#give dataset columns\n",
    "dataset.columns=[\n",
    "       \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial_Status\",\n",
    "       \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital_Gain\", \"Capital_Loss\",\n",
    "       \"Hours_per_week\", \"Country\", \"Target\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.278283Z",
     "start_time": "2019-06-07T03:17:39.254595Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.308139Z",
     "start_time": "2019-06-07T03:17:39.281978Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.314475Z",
     "start_time": "2019-06-07T03:17:39.310845Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.358041Z",
     "start_time": "2019-06-07T03:17:39.316165Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['Target'].replace(\" <=50K\",-1,inplace=True)\n",
    "dataset['Target'].replace(\" >50K\",1,inplace=True)\n",
    "dataset.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.407118Z",
     "start_time": "2019-06-07T03:17:39.361963Z"
    }
   },
   "outputs": [],
   "source": [
    "#get dummy variables whose are in categorical type\n",
    "def categorical_value(dataset):\n",
    "    dataset=pd.get_dummies(dataset)\n",
    "    return dataset\n",
    "dataset=categorical_value(dataset)\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.416850Z",
     "start_time": "2019-06-07T03:17:39.410732Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.427963Z",
     "start_time": "2019-06-07T03:17:39.418367Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_train_test(dataset):\n",
    "    train=len(dataset)*0.70\n",
    "    train=int(train)\n",
    "    test=len(dataset)-train\n",
    "    test=int(test)\n",
    "    train=dataset.head(train)\n",
    "    test=dataset.tail(test)\n",
    "    return train ,test\n",
    "\n",
    "train,test=split_train_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.439604Z",
     "start_time": "2019-06-07T03:17:39.429892Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.460422Z",
     "start_time": "2019-06-07T03:17:39.441454Z"
    }
   },
   "outputs": [],
   "source": [
    "def separate(dataset):\n",
    "    output = dataset['Target']\n",
    "    return dataset.drop('Target', axis=1), output\n",
    "train_x_data,train_y_data = separate(train)\n",
    "test_x_data,test_y_data=separate(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:17:39.470543Z",
     "start_time": "2019-06-07T03:17:39.462580Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x_data.shape,train_y_data.shape,test_x_data.shape,test_y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:18:20.635675Z",
     "start_time": "2019-06-07T03:18:11.932495Z"
    }
   },
   "outputs": [],
   "source": [
    "class SingleNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.epoch=1000\n",
    "        self.learning_rate=0.001\n",
    "    def gradient_descent(self,x_train_data,y_train_data,weights,bias):\n",
    "        \n",
    "        for i in range(self.epoch):\n",
    "            z=np.dot(weights.T,x_train_data.T)+bias\n",
    "            #print(\"z\",z.shape)\n",
    "            \n",
    "            sigmoid=np.divide(1,np.add(1,np.exp(-z)))\n",
    "#             print(\"sigmoid\",sigmoid.shape)\n",
    "            \n",
    "            activation=sigmoid\n",
    "#             print(\"activation\",activation.shape)\n",
    "            \n",
    "            dz=np.subtract(activation,y_train_data.T)\n",
    "#             print(\"x train data\",x_train_data.shape,z.shape)\n",
    "            \n",
    "            dw=np.dot(x_train_data.T,z.T)\n",
    "            dw=np.divide(dw,len(x_train_data))\n",
    "#             print(\"dw\",dw.shape)\n",
    "            \n",
    "            db = np.sum(dz,axis=1,keepdims=True)\n",
    "#             print(\"db\",db.shape)\n",
    "            db = np.divide(db,len(x_train_data))\n",
    "#             print(\"db1\",db.shape)\n",
    "            \n",
    "            weights=np.subtract(weights,(np.dot(self.learning_rate,dw)))\n",
    "#             print(\"weights\",weights.shape)\n",
    "\n",
    "            bias=np.subtract(bias,(np.dot(self.learning_rate,db)))\n",
    "#             print(\"bias\",bias.shape)\n",
    "            \n",
    "        return weights,bias\n",
    "    \n",
    "    def test(self,x_test_data,weights,bias):\n",
    "        y_predict = np.zeros((x_test_data.shape[0], 1), dtype=float)\n",
    "        z=np.dot(weights.T,x_test_data.T)+bias\n",
    "#         print(\"z\",z.shape)\n",
    "        \n",
    "        sigmoid=np.divide(1,np.add(1,np.exp(-z)))\n",
    "#         print(\"sigmoid\",sigmoid.shape)\n",
    "        \n",
    "        for i in (range(0, len(sigmoid))):\n",
    "                if round(sigmoid[i][0],2) <= 0.5:\n",
    "                    y_predict[i][0] = 0\n",
    "                else:\n",
    "                    y_predict[i][0] = 1\n",
    "        y_predict= np.reshape(y_predict, (len(y_predict), 1))\n",
    "        return y_predict\n",
    "    \n",
    "    \n",
    "    def accuracy(self, y_test_data, y_predict):\n",
    "        count=0\n",
    "        for i in range(0,len(y_test_data)):\n",
    "            if y_predict[i]==y_test_data[i]:\n",
    "                count = count + 1\n",
    "        \n",
    "        return count/len(y_test_data)*100\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "           \n",
    "def main():\n",
    "    obj=SingleNeuralNetwork()\n",
    "    \n",
    "    #convert train test data into array\n",
    "    x_train_data=np.array(train_x_data)\n",
    "    print(\"x train data\",x_train_data.shape)\n",
    "    y_train_data=np.array(train_y_data)\n",
    "    y_train_data=y_train_data.reshape(len(y_train_data),1)\n",
    "    print(\"y train data\",y_train_data.shape)\n",
    "    \n",
    "    \n",
    "    x_test_data=np.array(test_x_data)\n",
    "    print(\"x test data\",x_test_data.shape)\n",
    "    y_test_data=np.array(test_y_data)\n",
    "    y_test_data=y_test_data.reshape(len(y_test_data),1)\n",
    "    print(\"y test data\",y_test_data.shape)\n",
    "    \n",
    "    weights=107\n",
    "    bias=1\n",
    "    weights=np.full((weights+1,1),.1)\n",
    "    \n",
    "    \n",
    "    weights,bias=obj.gradient_descent(x_train_data,y_train_data,weights,bias)\n",
    "    print(\"weights\",weights)\n",
    "    print(\"bias\",bias)\n",
    "    \n",
    "    y_predict=obj.test(x_test_data,weights,bias)\n",
    "    print(\"y predict value\",y_predict)\n",
    "    \n",
    "    accuracy=on=obj.accuracy(y_test_data,y_predict)\n",
    "    print(\"final accuracy\",accuracy)\n",
    "     \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
