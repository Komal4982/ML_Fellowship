{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.412373Z",
     "start_time": "2019-06-07T03:15:09.856197Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.518454Z",
     "start_time": "2019-06-07T03:15:10.414276Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"classification.csv\")\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.524323Z",
     "start_time": "2019-06-07T03:15:10.520570Z"
    }
   },
   "outputs": [],
   "source": [
    "#give dataset columns\n",
    "dataset.columns=[\n",
    "       \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial_Status\",\n",
    "       \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital_Gain\", \"Capital_Loss\",\n",
    "       \"Hours_per_week\", \"Country\", \"Target\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.552356Z",
     "start_time": "2019-06-07T03:15:10.526253Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.586339Z",
     "start_time": "2019-06-07T03:15:10.554289Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.594858Z",
     "start_time": "2019-06-07T03:15:10.588368Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.635058Z",
     "start_time": "2019-06-07T03:15:10.597080Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['Target'].replace(\" <=50K\",-1,inplace=True)\n",
    "dataset['Target'].replace(\" >50K\",1,inplace=True)\n",
    "dataset.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.686502Z",
     "start_time": "2019-06-07T03:15:10.638029Z"
    }
   },
   "outputs": [],
   "source": [
    "#get dummy variables whose are in categorical type\n",
    "def categorical_value(dataset):\n",
    "    dataset=pd.get_dummies(dataset)\n",
    "    return dataset\n",
    "dataset=categorical_value(dataset)\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.692613Z",
     "start_time": "2019-06-07T03:15:10.688499Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.707963Z",
     "start_time": "2019-06-07T03:15:10.694595Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_train_test(dataset):\n",
    "    train=len(dataset)*0.70\n",
    "    train=int(train)\n",
    "    test=len(dataset)-train\n",
    "    test=int(test)\n",
    "    train=dataset.head(train)\n",
    "    test=dataset.tail(test)\n",
    "    return train ,test\n",
    "\n",
    "train,test=split_train_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.719855Z",
     "start_time": "2019-06-07T03:15:10.710653Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.738909Z",
     "start_time": "2019-06-07T03:15:10.723637Z"
    }
   },
   "outputs": [],
   "source": [
    "def separate(dataset):\n",
    "    output = dataset['Target']\n",
    "    return dataset.drop('Target', axis=1), output\n",
    "train_x_data,train_y_data = separate(train)\n",
    "test_x_data,test_y_data=separate(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:10.751306Z",
     "start_time": "2019-06-07T03:15:10.744652Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x_data.shape,train_y_data.shape,test_x_data.shape,test_y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:10:07.600487Z",
     "start_time": "2019-06-07T03:10:07.560180Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T03:15:33.129191Z",
     "start_time": "2019-06-07T03:15:10.756556Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiLayerNeural:\n",
    "    def __init__(self):\n",
    "        self.alpha = 0.1\n",
    "        self.epoch = 1000\n",
    "    \n",
    "        \n",
    "    def Train(self,x_train_data, y_train_data):\n",
    "        weight=[]\n",
    "        bias=[]\n",
    "        # Initializing layers\n",
    "        layers=[x_train_data.shape[1],4,5,3,1]\n",
    "        db=0.0\n",
    "        a = [0] * len(layers)\n",
    "        z = [0] * len(layers)\n",
    "        A = [0] * len(layers)\n",
    "        dg = [0] * len(layers)\n",
    "        da = [0] * len(layers)\n",
    "        dz = [0] * len(layers)\n",
    "        db = [0] * len(layers)\n",
    "        dw = [0] * len(layers)\n",
    "    \n",
    "        a[0]=x_train_data.T\n",
    "        \n",
    "        # Initializing weights and bias for all layers     \n",
    "   \n",
    "        for i in range(len(layers)):\n",
    "            weight.append((np.random.randn(layers[i],layers[i-1])*0.001))\n",
    "    #             print(weight)\n",
    "            bias.append(np.zeros((layers[i],1)))\n",
    "    #             print(bias)\n",
    "        \n",
    "        # forward propagation         \n",
    "        for length in range(self.epoch):\n",
    "            for i in range(1,len(layers)):\n",
    "                z[i] = np.dot(weight[i],a[i-1])+bias[i]\n",
    "                a[i] = (1 / (1 + np.exp(-z[i])))\n",
    "            \n",
    "        # backward propagation\n",
    "        \n",
    "            for i in reversed(range(1,len(layers))):\n",
    "                da[i]=(-(y_train_data.T/a[i])+((1-y_train_data.T)/(1-a[i])))\n",
    "                dg[i] = (1 / (1 + np.exp(-z[i]))) * (1 - (1 / (1 + np.exp(-z[i]))))\n",
    "                dz[i]=da[i]*dg[i]\n",
    "                dw[i]=(np.dot(dz[i],a[i-1].T)/len(x_train_data))\n",
    "                db[i]=(np.sum(dz[i],axis=1,keepdims=True)/len(x_train_data))\n",
    "                weight[i]=(weight[i]-(np.dot(self.alpha,dw[i])))\n",
    "                bias[i]=(bias[i]-(np.dot(self.alpha,db[i])))\n",
    "        return weight,bias\n",
    "\n",
    "    def Test_data(self, x_test_data, weight,bias): \n",
    "        layers=[x_test_data.shape[1],4,5,3,1]\n",
    "        \n",
    "        a = [0] * len(layers)\n",
    "        z = [0] * len(layers)\n",
    "        a[0]=x_test_data.T\n",
    "        \n",
    "        # testing test data on Activation/Hypothesis Function \n",
    "        for i in range(1,len(layers)):\n",
    "            z[i] = np.dot(weight[i],a[i-1])+bias[i]\n",
    "            a[i] = (1 / (1 + np.exp(-z[i])))\n",
    "#         print(len(a))\n",
    "        return a[-1]\n",
    "          \n",
    "    def Accuracy(self, y_test_data, y_predict):\n",
    "        y_predict = np.nan_to_num(y_predict)\n",
    "   \n",
    "        test_accuracy = 100 - (np.mean(np.abs(y_predict - y_test_data)) * 100)        \n",
    "        return test_accuracy\n",
    "\n",
    "def main():\n",
    "    # creates class object \n",
    "    obj = MultiLayerNeural()\n",
    "    \n",
    "    # convert data into numpy array     \n",
    "    x_train_data = np.array(train_x_data)\n",
    "    y_train_data = np.array(train_y_data)\n",
    "    y_train_data = y_train_data.reshape(len(y_train_data),1)\n",
    "        \n",
    "    x_test_data = np.array(test_x_data)\n",
    "    y_test_data = np.array(test_y_data)\n",
    "    y_test_data = y_test_data.reshape(len(y_test_data),1)\n",
    "    \n",
    "#     print(\"x_train_data\",x_train_data.shape)\n",
    "#     print(\"y_train_data\",y_train_data.shape) \n",
    "#     print(\"x_test_data\",x_test_data.shape)\n",
    "#     print(\"y_test_data\",y_test_data.shape)  \n",
    "    \n",
    "       \n",
    "     # calling method by class object to get weights and bias\n",
    "    weights,bias = obj.Train(x_train_data, y_train_data)\n",
    "#     print(\"weight\",weights)\n",
    "#     print(\"bias\",bias)\n",
    "    # getting prediction values    \n",
    "    y_predict_train = obj.Test_data(x_train_data, weights,bias)\n",
    "    y_predict_test = obj.Test_data(x_test_data, weights,bias)\n",
    "\n",
    "    # getting accuracy     \n",
    "    acc_train=obj.Accuracy(y_predict_train,y_train_data)\n",
    "    print(\"\\n\\naccuracy of train data=\",acc_train)\n",
    "    \n",
    "    acc_test=obj.Accuracy(y_predict_test,y_test_data)\n",
    "    print(\"accuracy of test data=\",acc_test)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
